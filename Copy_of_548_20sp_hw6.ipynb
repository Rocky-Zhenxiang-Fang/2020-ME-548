{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 548_20sp_hw6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RockyZhenXiang/2020-ME-548/blob/master/Copy_of_548_20sp_hw6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qz2av61Xgua",
        "colab_type": "text"
      },
      "source": [
        "# 548 20sp hw6 due 5p Fri May 15 on Canvas\n",
        "\n",
        "***You are welcome (and encouraged) to:***\n",
        "- work with others -- each individual must submit their own writeup;\n",
        "- use analytical and numerical computational tools -- specify the tool(s) in sourcecode and/or text;\n",
        "- consult websites, textbooks, and other materials -- include full citation(s).\n",
        "\n",
        "**Important:** before you do any work in this Colaboratory notebook, click \"File -> Save a copy in Drive ...\" and rename the file to something memorable.\n",
        "\n",
        "**Also important:** To produce a .pdf for submission to Canvas from this Colaboratory notebook, click \"File -> Print\" (or press Ctrl/Cmd + P), and choose \"Save to PDF\" (on OSX) or \"Microsoft Print to PDF\" (on Windows) as your printer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLms0q_OolBH",
        "colab_type": "text"
      },
      "source": [
        "# [insert your name]\n",
        "\n",
        "***Purpose:*** *provide feedback so we can better support your learning; graded solely on participation.*\n",
        "\n",
        "(a) *Approximately how many hours did you spend on this assignment?*\n",
        "\n",
        "(b) *Were there specific problems that took much longer than others?*\n",
        "\n",
        "(c) *What class meeting(s) / office hour(s) did you participate in this week?*\n",
        "\n",
        "(d) *What timezone(s) were you working in this week?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVZVZxJvtcOe",
        "colab_type": "text"
      },
      "source": [
        "# simulating random variables\n",
        "\n",
        "***Purpose:*** *this problem will show you how to work with (Gaussian/normal) random variables in scientific computing by determining or estimating their mean and covariance.*\n",
        "\n",
        "Let $w:\\Omega\\rightarrow\\mathbb{R}^k$ be a random vector obtained by concatenating $k$ independent standard normal (scalar) random variables.\n",
        "\n",
        "The *sample covariance* $\\Sigma_N$ associated with a dataset $\\left\\{w_j\\right\\}_{j=1}^N\\subset\\mathbb{R}^k$ of outcomes from $w$ is defined by\n",
        "$$\\Sigma_N = \\frac{1}{N-1}\\sum_{j=1}^N(w_j - \\bar{w}_N)(w_j - \\bar{w}_N)^T$$\n",
        "where $\\bar{w}_N$ denotes the *sample mean*\n",
        "$$\\bar{w}_N = \\frac{1}{N}\\sum_{j=1}^Nw_j.$$\n",
        "\n",
        "According to the [Law of Large Numbers](https://en.wikipedia.org/wiki/Law_of_large_numbers),  the limits \n",
        "$\\bar{w} = \\lim_{N\\rightarrow\\infty}\\bar{w}_N$ \n",
        "and\n",
        "$\\Sigma = \\lim_{N\\rightarrow\\infty}\\Sigma_N$ \n",
        "are the mean and covariance of $w$:  $\\bar{w} = \\operatorname{E}[w]$, $\\Sigma = \\operatorname{Cov}[w]$.\n",
        "\n",
        "(a) *Determine the mean and covariance of $w$.*\n",
        "\n",
        "(b) *For several choices of $k$ and $N$, generate datasets $\\left\\{w_j\\right\\}_{j=1}^N\\subset\\mathbb{R}^k$ by calling the ``np.random.randn()`` function $k\\times N$ times.  Compute the sample mean and sample covariance and compare with your answer from (a).  How big does $N$ need to be so that the sample mean and covariance agree with the true mean and covariance to one decimal place in your experiments when $k = 2$?*\n",
        "\n",
        "**Hint:** you need only specify an order of magnitude for $N$; you will use this $N$ in the remainder of this problem.\n",
        "\n",
        "With $M = \\left[\\begin{array}{cc} 1 & 2 \\\\ 3 & 4 \\end{array}\\right]$ and $b = \\left[\\begin{array}{c} -1 \\\\ +1 \\end{array}\\right]$, let $x = M w + b$ be a new Gaussian random vector.\n",
        "\n",
        "(c) *Determine the mean and covariance of $x$.*\n",
        "\n",
        "(d) *Compute the sample mean and sample covariance for a new dataset $\\left\\{M w_j\\right\\}_{j=1}^N\\subset\\mathbb{R}^2$ where the $w_j$'s are generated as in (b) and compare with your answer from (c).*\n",
        "\n",
        "(e) *Suppose now that you wish to generate samples from a Gaussian random vector with covariance $Q = Q^T > 0$.  Propose a computational procedure and apply your procedure with $Q = \\left[\\begin{array}{cc} 1 & 2 \\\\ 2 & 4 \\end{array}\\right]$*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S59sqSMnxvK1",
        "colab_type": "text"
      },
      "source": [
        "# linear least-squares\n",
        "\n",
        "***Purpose:*** *this problem shows the versatility of least-squares estimation by applying it to curve-fitting.*\n",
        "\n",
        "We sample a signal $y:[t_0,t_f]\\rightarrow\\mathbb{R}$ at times $\\left\\{ t_j \\right\\}_{j=1}^N\\subset[t_0,t_f]$, and seek to represent the signal as a linear combination of basis elements\n",
        "$$y(t) \\approx \\sum_{b\\in B} c_b \\cdot b(t)$$\n",
        "where $B$ is a finite set with $|B| = k$ elements, each $b\\in B$ is a signal $b:[t_0,t_f]\\rightarrow\\mathbb{R}$, and at each $t_j$ we obtain a noisy observation\n",
        "$$z_j = y(t_j) + \\eta_j$$\n",
        "where $\\eta_j\\in\\mathbb{R}$ is unknown \"noise\".\n",
        "\n",
        "(a) *Formulate this as a linear estimation problem of the form\n",
        "$$z = H c + \\eta$$\n",
        "where $z,\\eta\\in\\mathbb{R}^N$, $c\\in\\mathbb{R}^k$, $H\\in\\mathbb{R}^{N\\times k}$ (i.e. specify the entries in the vectors $z, c, \\eta$ and matrix $H$ in terms of the problem data).*\n",
        "\n",
        "(b) *Implement an algorithm that takes $\\left\\{ t_j \\right\\}_{j=1}^N$, $\\left\\{ z_j \\right\\}_{j=1}^N$, and $B$ as arguments and returns the linear least-squares estimate $\\hat{c}$ that minimizes the cost function\n",
        "$$J = (z - H \\hat{c})^T (z - H\\hat{c}).$$*\n",
        "\n",
        "(c) *Apply your algorithm from (b.) to a problem of your choosing with at least three basis functions and noise with nonzero variance.  Plot the sampled data, the estimated signal, and the actual signal.*\n",
        "\n",
        "***Hint:*** test your algorithm using a signal that is exactly represented as a linear combination of your basis functions, and low- (or no-)variance noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl8oDrx3o3f-",
        "colab_type": "text"
      },
      "source": [
        "# hybrid random variables\n",
        "\n",
        "***Purpose:*** *this problem shows that random variables need not be purely \"continuous\" or \"discrete\".*\n",
        "\n",
        "Consider the random variable $x:\\Omega\\rightarrow\\mathbb{R}$ obtained from a standard normal random variable $y:\\Omega\\rightarrow\\mathbb{R}$ as follows:\n",
        "$$\\forall\\omega\\in\\Omega : x(\\omega) = y(\\omega)\\ \\text{if}\\ y(\\omega) > 0,\\ \\text{otherwise}\\ 0.$$\n",
        "\n",
        "(a) *Does $x$ have a probability density function?  (i.e. does there exist a function $\\rho:\\mathbb{R}\\rightarrow[0,\\infty)$ such that the probability that $x$ takes on values in the set $W\\subset\\mathbb{R}$ is $\\int_W \\rho(\\omega) d\\omega$?)*\n",
        "\n",
        "(b) *Provide an analytical expression and numerical value for $E[x]$ (the analytical expression can involve an improper integral).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhnv5zkyC-y6",
        "colab_type": "text"
      },
      "source": [
        "#Solution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxWtFpq2MLtQ",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s3Dlj4hMJbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%pdb off\n",
        "import numpy as np\n",
        "# limit number of decimal places printed for floating-point numbers\n",
        "np.set_printoptions(precision=3)\n",
        "\n",
        "# scipy = scientific Python, implements operations on arrays / matrices\n",
        "import scipy as sp\n",
        "# linalg = linear algebra, implements eigenvalues, matrix inverse, etc\n",
        "from scipy import linalg as la\n",
        "# optimize = optimization, root finding, etc\n",
        "from scipy import optimize as op\n",
        "\n",
        "# produce matlab-style plots\n",
        "import matplotlib as mpl\n",
        "# increase font size on plots\n",
        "mpl.rc('font',**{'size':18})\n",
        "# use LaTeX to render symbols\n",
        "mpl.rc('text',usetex=False)\n",
        "# animation\n",
        "from matplotlib import animation as animation\n",
        "from IPython.display import HTML\n",
        "mpl.rc('animation', html='jshtml')\n",
        "# Matlab-style plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# symbolic computation, i.e. computer algebra (like Mathematica, Wolfram Alpha)\n",
        "import sympy as sym\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  COLAB = True\n",
        "  print('Colaboratory Notebook')\n",
        "except:\n",
        "  COLAB = False\n",
        "  print('Jupyter Notebook')\n",
        "\n",
        "# Colab notebook\n",
        "if COLAB:\n",
        "  # pip = Python package manager; \"!\" means \"run at system level\"\n",
        "  !pip install slycot\n",
        "  !pip install control\n",
        "  \n",
        "  # render SymPy equations nicely in Colaboratory Notebook\n",
        "  def colab_latex_printer(exp,**options):\n",
        "    from google.colab.output._publish import javascript\n",
        "    url = \"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=default\"\n",
        "    javascript(url=url)\n",
        "    return sym.printing.latex(exp,**options)\n",
        "  \n",
        "  sym.init_printing(use_latex=\"mathjax\",latex_printer=colab_latex_printer)\n",
        "\n",
        "# Jupyter notebook\n",
        "else:\n",
        "  init_printing(use_latex='mathjax')\n",
        "\n",
        "# Python's Control Systems Toolbox\n",
        "import control as ctrl\n",
        "\n",
        "# SciPy module that implements many of the routines in ctrl\n",
        "from scipy import signal as sig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMqjkdAtDBRE",
        "colab_type": "text"
      },
      "source": [
        "##Simulating random variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZYH_C9oDQgg",
        "colab_type": "text"
      },
      "source": [
        "###(a)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mngrvQtdLK85",
        "colab_type": "text"
      },
      "source": [
        "For mean, we know that when N approaches infinity, we can replace the summation with integral, thus, we have:\n",
        "$$\\bar{w} = E[w]= \\lim_{N\\rightarrow\\infty}(\\frac{1}{N}\\sum_{j=1}^Nw_j) = \\frac{1}{n}\\int_{0}^{\\infty}w(n)dn.$$\n",
        "where n represents the independent variable.\n",
        "\n",
        "For covarience:\n",
        "$$Cov[w]  = \\Sigma = E[(w-E[w])(w-E[w])^T]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oG5k10HH_cX",
        "colab_type": "text"
      },
      "source": [
        "###(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Abzq-jBLNbh",
        "colab_type": "text"
      },
      "source": [
        "By looking at the document, we know that np.random.randn always produces number based on Normal Gaussian Distribution, meaning that the *mean = 0* and the *covariance = 1*.\n",
        "\n",
        "By trial and error, I found that when N is bigger than 500, the error between the true value and the dataset is smaller than one decimal place constantly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5TDm7RLMmzO",
        "colab_type": "code",
        "outputId": "37c882fe-a5b7-420f-d5fa-7db265c24592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "k = 2\n",
        "N = 500\n",
        "# w = np.zeros((k,N))\n",
        "\n",
        "# for i in range(k):\n",
        "#   for j in range(N):\n",
        "#     w[i,j] = np.random.randn()\n",
        "w = np.random.randn(k,N)\n",
        "\n",
        "## mean\n",
        "total = np.zeros(2)\n",
        "for i in range(N):\n",
        "  total = total + w[:,i]\n",
        "\n",
        "mean = total / N\n",
        "print(\"The differece between mean and 0 are {}\".format(mean-0))\n",
        "\n",
        "# Cov\n",
        "co = np.zeros((2,2))\n",
        "for i in range(N):\n",
        "  co += (np.reshape((w[:,i]-mean),(2,1))*(w[:,i]-mean).T)\n",
        "\n",
        "co = co / (N-1)\n",
        "print(\"The differece between covariance and 1 are {}\".format(co-1))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The differece between mean and 0 are [-0.054  0.008]\n",
            "The differece between covariance and 1 are [[ 0.07  -0.953]\n",
            " [-0.953 -0.027]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr3LkIdxMbbW",
        "colab_type": "text"
      },
      "source": [
        "###(c)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhR-HAquMcdw",
        "colab_type": "text"
      },
      "source": [
        "By formula in the notes, we see that:\n",
        "\n",
        "$$mean(x) = E(x) = ME(w)+b $$\n",
        "\n",
        "$$Cov(x) = M\\Sigma M^T$$\n",
        "\n",
        "Where $E(w)$ and $\\Sigma$ are defined in preious problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_84fa2YPs_R",
        "colab_type": "text"
      },
      "source": [
        "###(d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jFpgzLdPuUp",
        "colab_type": "text"
      },
      "source": [
        "The result after excuting the code is:\n",
        "\n",
        "The mean obtained by changing the data is [0.033 -0.004]\n",
        "\n",
        "The mean obtained by the formula is [ 1.033 -1.004]\n",
        "\n",
        "The covariance obtained by changing the data is [[ 4.784 10.507]\n",
        " [10.507 23.912]]\n",
        "\n",
        "The covariance obtained by the formula is [[ 4.773 10.513]\n",
        " [10.513 23.909]]\n",
        "\n",
        " For mean, there is a difference of b = [-1,1] since the new data set does not ask us to add b into it.\n",
        " \n",
        " For covariance, the result of both method are quite similar, the difference might come from rounding error.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdHFZI8aQzde",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d1281018-e3c9-47c6-eb2e-af8613287c4b"
      },
      "source": [
        "M = np.array([[1,2],[3,4]])\n",
        "b = np.array([[-1],[1]])\n",
        "x = M@w\n",
        "\n",
        "total = np.zeros(2)\n",
        "for i in range(N):\n",
        "  total = total + x[:,i]\n",
        "\n",
        "mean_x = total / N\n",
        "\n",
        "# Cov\n",
        "co_x = np.zeros((2,2))\n",
        "for i in range(N):\n",
        "  co_x += (np.reshape((x[:,i]-mean),(2,1))*(x[:,i]-mean).T)\n",
        "\n",
        "co_x = co_x / (N-1)\n",
        "\n",
        "meanT = np.reshape(mean,(2,1))\n",
        "mean_x_ana = M@meanT-b\n",
        "co_x_ana = M@co@M.T\n",
        "print(\"The mean obtained by changing the data is {}\".format(mean_x))\n",
        "print(\"The mean obtained by the formula is {}\".format(mean_x_ana))\n",
        "print(\"The covariance obtained by changing the data is {}\".format(co_x))\n",
        "print(\"The covariance obtained by the formula is {}\".format(co_x_ana))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean obtained by changing the data is [-0.039 -0.131]\n",
            "The mean obtained by the formula is [[ 0.961]\n",
            " [-1.131]]\n",
            "The covariance obtained by changing the data is [[ 5.153 11.468]\n",
            " [11.468 26.359]]\n",
            "The covariance obtained by the formula is [[ 5.153 11.47 ]\n",
            " [11.47  26.34 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok2hM0pBaZkT",
        "colab_type": "text"
      },
      "source": [
        "###(e)\n",
        "For a random vector $w$, we can find its $\\Sigma$ by "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YJgf4XxhR0m",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LouLcFugGPzl",
        "colab_type": "text"
      },
      "source": [
        "## Linear least square\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cUg6MsWGUr2",
        "colab_type": "text"
      },
      "source": [
        "###(a)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqSvbMJHGV50",
        "colab_type": "text"
      },
      "source": [
        "$z$ is a N by 1 vector, each of its element represents a measurement at a certain time. \n",
        "\n",
        "$\\eta$ is also a N by 1 vector, each of its element represents a noise at a certain time.\n",
        "\n",
        "$c$ is a k by n verctor, each of its element means a *weight* of its corrosponding $b_i$ element that makes up *z*.\n",
        "\n",
        "$H$ is a N by k matrix, each of its row represents a measurement of all $b_i$ in a certain time; each of its column represents a basis $b_i$ over all sampling time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXmxhwFlKtgb",
        "colab_type": "text"
      },
      "source": [
        "###(b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snggosfpKu4_",
        "colab_type": "text"
      },
      "source": [
        "To minimize $J$, we need to find $\\hat{c}$ that makes $DJ = 0$ and $D^2J > 0$\n",
        "\n",
        "By taking the derivative of $J$, $DJ(\\hat{c})$ is:\n",
        "\n",
        "$$DJ(\\hat{c}) = H^TH\\hat{c} - H^Tz$$\n",
        "\n",
        "and also, by taking two derivative of J, we get $H^TH > 0$, which means that $\\hat{c}$ will always be a local minimum if it satisfies $DJ(\\hat{c}) = 0$\n",
        "\n",
        "Since both $H$ and $z$ are known, the equation can be rearranged into:\n",
        "\n",
        "$$\\hat{c} = (H^TH)^{-1}H^Tz$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03kYtrG6TbWX",
        "colab_type": "text"
      },
      "source": [
        "###(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uQUVArrTe3Q",
        "colab_type": "text"
      },
      "source": [
        "To setup the data, I choose my three basis fucntion as $5*\\sin(t), 2*\\cos(2t), t^2$ and my noise is $\\cos(1000t)$. Sampling in $t = [0,2\\pi]$ seconds with 1000 sampling points**. Take $c = [1,1,1]^T$ and find $\\hat{c}$ by the algrithm above. \n",
        "![alt text](https://drive.google.com/uc?id=10_weM3gG74HMYSuPLCzkMBrYveOT27-a)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PjkRneOUt5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_ = np.linspace(0,2*np.pi,1000)\n",
        "b1_ = 5*np.sin(t_)\n",
        "b2_ = 2*np.cos(2*t_)\n",
        "b3_ = t_**2\n",
        "\n",
        "noise_ = np.cos(1000*t_)\n",
        "c = np.array([1,1,1])\n",
        "z_ = np.zeros((len(t_),1))\n",
        "\n",
        "for i in range(len(t_)):\n",
        "  b = np.array([b1_[i],b2_[i],b3_[i]])  \n",
        "  z_[i] = np.dot(c,b)+noise_[i]\n",
        "\n",
        "H_ = np.zeros((len(t_),3))\n",
        "H_[:,0] = b1_\n",
        "H_[:,1] = b2_\n",
        "H_[:,2] = b3_\n",
        "\n",
        "c_hat = np.linalg.inv(H_.T.dot(H_)).dot(H_.T).dot(z_)\n",
        "\n",
        "z_est = np.zeros((len(t_),1))\n",
        "\n",
        "for i in range(len(t_)):\n",
        "  b = np.array([b1_[i],b2_[i],b3_[i]])  \n",
        "  z_est[i] = np.dot(np.reshape(c_hat,(1,3)),b)\n",
        "\n",
        "\n",
        "plt.figure(figsize=((15,20)))\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(t_,b1_, label = \"$b_1, 5sin(t)$\")\n",
        "plt.plot(t_,b2_, label = \"$b_2, 2cos(2t)$\")\n",
        "plt.plot(t_,b3_, label = \"$b_3, t^2$\")\n",
        "plt.plot(t_,z_, label = \"actual signal\")\n",
        "plt.xlabel(\"time (sec)\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.title(\"Sampled data & Actual signal\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(t_,b1_, label = \"$b_1, 5sin(t)$\")\n",
        "plt.plot(t_,b2_, label = \"$b_2, 2cos(2t)$\")\n",
        "plt.plot(t_,b3_, label = \"$b_3, t^2$\")\n",
        "plt.plot(t_,z_est, label = \"estimated signal\")\n",
        "plt.xlabel(\"time (sec)\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.title(\"Sampled data & Estimated signal\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(t_,z_,label = \"actual signal\")\n",
        "plt.plot(t_,z_est,label = \"estimated signal\")\n",
        "plt.xlabel(\"time (sec)\")\n",
        "plt.ylabel(\"value\")\n",
        "plt.title(\"Actual signal V.S. Estimated signal\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn3AayUkiMYO",
        "colab_type": "text"
      },
      "source": [
        "## Hybrid random variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZIUdvFCiP8d",
        "colab_type": "text"
      },
      "source": [
        "###(a)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rUGc6r8iRTM",
        "colab_type": "text"
      },
      "source": [
        "Yes, $x(w)$ has a probability density funciton. Since the probability of select a number will equal to $y(w)$, which is in standard normal distribution, if $w>0$, then for $w>0$, the probability density function of $x(w)$ will have a similar shpae to the standard normal distribution when $w>0$. However, since $x(w) = 0$ when $w\\leqslant0$ and the standard normal distribution is symmatric about 0, the probility density function needs to mlultipy by 2. Thus, we have:\n",
        "\n",
        "$$\\rho(w) = \\begin{cases} \\sqrt{\\frac{2}{\\pi}}e^{-\\frac{1}{2}w^2}, w>0 \\\\  0, w\\leqslant0   \\end{cases}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pMeAuVurfMR",
        "colab_type": "text"
      },
      "source": [
        "###(b)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRRha49crhKG",
        "colab_type": "text"
      },
      "source": [
        "The definition of expected value is:\n",
        "$$E(X) = \\int_ww*\\rho(w)dw$$\n",
        "where $\\rho(w)$ is the probability function of $X(w)$\n",
        "\n",
        "Thus, the expect value of the half standard normal distribution is:\n",
        "\n",
        "$$E(x(w)) = \\int_0^\\infty w*\\sqrt{\\frac{2}{\\pi}}e^{-\\frac{1}{2}w^2}dw$$\n",
        "\n",
        "By variable transformation using $u = \\frac{w^2}{2}$ the equation turns into:\n",
        "$$E(x(w)) = \\sqrt{\\frac{2}{\\pi}}\\int_0^\\infty e^{-u}du = \\sqrt{\\frac{2}{\\pi}}*-(e^{-u})|_{u = 0}^{u = \\infty} = \\sqrt{\\frac{2}{\\pi}}$$"
      ]
    }
  ]
}